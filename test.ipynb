{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSgeYk_58FVK",
        "outputId": "44306438-196e-4b31-a01d-2cc7c94f6652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GVS-3'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), 11.46 KiB | 2.29 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SluKate/GVS-3.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y nvidia-cuda-toolkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i95Ci2XlC02K",
        "outputId": "6aecb8cc-b7a7-42ce-abcc-ec24db62868d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "nvidia-cuda-toolkit is already the newest version (11.5.1-1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGrA5pU_8Xov",
        "outputId": "e28569d5-362f-4f35-e5a5-a731be6caa05"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mGVS-3\u001b[0m/  GVS-3.2.ipynb  linearlayer.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GVS-3/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvKhHSUr8ZKK",
        "outputId": "5f86b8ff-3c2d-414a-e97b-08f9c7b82fdb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GVS-3/GVS-3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb9KMNVQ8eBr",
        "outputId": "79797d0f-6748-46a2-869e-deac1c4e5aea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GVS-3.2.ipynb  linearlayer.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ninja-build\n",
        "!apt-get install build-essential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLlzt7Zu8i-8",
        "outputId": "882a6480-31ec-495e-c3c5-ae39ba1604a7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ninja-build is already the newest version (1.10.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!gcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaE9jdXr9RGG",
        "outputId": "aeb78310-5471-49a8-dbaa-1c53a0d73ac4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install gcc-9 g++-9\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3xM77WmOsbB",
        "outputId": "34748720-38b2-4613-fe05-0e02b39c6902"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Ign:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 257 kB in 2s (148 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++-9 is already the newest version (9.5.0-1ubuntu1~22.04).\n",
            "gcc-9 is already the newest version (9.5.0-1ubuntu1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 100\n",
        "!sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 100\n",
        "\n",
        "!sudo update-alternatives --config gcc\n",
        "!sudo update-alternatives --config g++\n",
        "\n",
        "!gcc --version\n",
        "!g++ --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8sbSrDNOudu",
        "outputId": "85efa1b9-0207-4319-a0ff-abda7027daeb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is only one alternative in link group gcc (providing /usr/bin/gcc): /usr/bin/gcc-9\n",
            "Nothing to configure.\n",
            "There is only one alternative in link group g++ (providing /usr/bin/g++): /usr/bin/g++-9\n",
            "Nothing to configure.\n",
            "gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "g++ (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import linearlayer"
      ],
      "metadata": {
        "id": "PFW82lsW9qID"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.cpp_extension as cpp_extension\n",
        "import unittest\n",
        "\n",
        "# Архитектура CUDA\n",
        "os.environ['TORCH_CUDA_ARCH_LIST'] = '7.5;8.0'\n",
        "\n",
        "# Компиляция CUDA-расширения\n",
        "linearlayer = cpp_extension.load(\n",
        "    name='linearlayer',\n",
        "    sources=['linearlayer.cu'],\n",
        "    extra_cuda_cflags=['-gencode', 'arch=compute_75,code=sm_75']\n",
        ")\n",
        "\n",
        "class TestDotProductCuda(unittest.TestCase):\n",
        "    def __init__(self, num_tests=1, *args, **kwargs):\n",
        "        super(TestDotProductCuda, self).__init__(*args, **kwargs)\n",
        "        self.num_tests = num_tests\n",
        "\n",
        "    def runTest(self):\n",
        "        results = []\n",
        "        for _ in range(self.num_tests):\n",
        "            m = 5  # количество примеров\n",
        "            k = 3  # количество входных признаков\n",
        "            n = 4  # количество выходных признаков\n",
        "\n",
        "            # Создайте тензоры\n",
        "            x = torch.randn(m, k).cuda()  # Входной тензор\n",
        "            w = torch.randn(n, k).cuda()  # Тензор весов\n",
        "            b = torch.randn(n).cuda()      # Тензор смещений\n",
        "\n",
        "            # Вычисление с помощью расширения\n",
        "            cuda_result = linearlayer.my_forward_linear(x, w, b)\n",
        "\n",
        "            linear_layer = torch.nn.Linear(k, n).cuda()\n",
        "            with torch.no_grad():\n",
        "                linear_layer.weight.copy_(w)  # Устанавливаем веса\n",
        "                linear_layer.bias.copy_(b)     # Устанавливаем смещения\n",
        "                y_builtin = linear_layer(x)     # Вызов библиотечной функции\n",
        "\n",
        "            # Проверка совпадения результатов с приемлемой точностью\n",
        "            self.assertTrue(torch.allclose(cuda_result, y_builtin, atol=1e-6),\n",
        "                            f\"Results do not match: CUDA result = {cuda_result}, PyTorch result = {y_builtin}\")\n",
        "\n",
        "            # Преобразование тензоров в NumPy\n",
        "            results.append((cuda_result.detach().cpu().numpy(), y_builtin.detach().cpu().numpy()))\n",
        "\n",
        "        for i, (cuda_result, torch_result) in enumerate(results):\n",
        "            print(f\"Test {i + 1}: CUDA result = \\n{cuda_result},\\n PyTorch result = \\n{torch_result}\\n\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    num_tests = int(input(\"Введите количество тестов: \"))  # Ввод количества тестов\n",
        "    # Создаем тестовый набор\n",
        "    suite = unittest.TestSuite()\n",
        "    suite.addTest(TestDotProductCuda(num_tests=num_tests))\n",
        "    unittest.TextTestRunner().run(suite)\n"
      ],
      "metadata": {
        "id": "C6bsdtsJ_wtC",
        "outputId": "756cacc6-4605-4b0c-d64b-ba4d568c8094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введите количество тестов: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.362s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1: CUDA result = \n",
            "[[ 1.9112868   1.1171244  -1.3567338  -1.3373904 ]\n",
            " [ 1.4314034   1.1907101  -0.8126314  -1.2536358 ]\n",
            " [ 1.1036934   1.0439898  -0.48358998 -1.0921097 ]\n",
            " [-1.8847437   1.3292809   1.5620627   4.116872  ]\n",
            " [ 0.9215004   0.06917584 -0.33757943 -1.0781134 ]],\n",
            " PyTorch result = \n",
            "[[ 1.911287    1.1171244  -1.3567338  -1.3373905 ]\n",
            " [ 1.4314034   1.1907101  -0.8126314  -1.2536358 ]\n",
            " [ 1.1036934   1.0439897  -0.48358998 -1.0921096 ]\n",
            " [-1.8847437   1.3292809   1.5620627   4.116872  ]\n",
            " [ 0.92150044  0.06917584 -0.33757943 -1.0781134 ]]\n",
            "\n",
            "Test 2: CUDA result = \n",
            "[[-0.14660183 -1.5228994   0.4673218  -0.78254354]\n",
            " [-0.6611709  -0.18384695 -1.2055745   0.22811282]\n",
            " [ 1.0994222  -1.4229728   1.7196178  -2.2288678 ]\n",
            " [ 1.1223315  -2.3550603   3.1103303  -3.099592  ]\n",
            " [ 0.37547863 -1.8824222   0.28672877 -0.505186  ]],\n",
            " PyTorch result = \n",
            "[[-0.1466018  -1.5228994   0.4673218  -0.78254354]\n",
            " [-0.66117084 -0.18384695 -1.2055745   0.22811288]\n",
            " [ 1.0994221  -1.4229728   1.7196178  -2.2288678 ]\n",
            " [ 1.1223316  -2.3550603   3.1103303  -3.099592  ]\n",
            " [ 0.37547866 -1.8824222   0.2867288  -0.5051861 ]]\n",
            "\n",
            "Test 3: CUDA result = \n",
            "[[-1.1430382  -0.11868852  0.89804804 -1.801733  ]\n",
            " [-1.670131   -1.01415     0.6997484  -1.2075491 ]\n",
            " [-0.520639    1.9166154  -0.17693314  1.7632985 ]\n",
            " [-0.6911247  -0.5691464   0.38658157 -1.1956105 ]\n",
            " [-1.336685    0.46666527  0.11108989  0.98770905]],\n",
            " PyTorch result = \n",
            "[[-1.1430382  -0.11868852  0.89804804 -1.801733  ]\n",
            " [-1.670131   -1.0141499   0.6997484  -1.2075491 ]\n",
            " [-0.520639    1.9166154  -0.17693314  1.7632985 ]\n",
            " [-0.6911247  -0.5691464   0.38658157 -1.1956105 ]\n",
            " [-1.336685    0.46666527  0.11108986  0.98770905]]\n",
            "\n",
            "Test 4: CUDA result = \n",
            "[[-0.5525446   2.740004    2.1684823  -1.622999  ]\n",
            " [ 0.6148312   1.5872622   1.5968837  -0.61821735]\n",
            " [ 0.73346364  0.2276063   1.987133    0.60149515]\n",
            " [ 0.5785128   0.08272111  3.0254755  -0.34089282]\n",
            " [ 0.86048615  2.200085    0.31724226 -0.10460892]],\n",
            " PyTorch result = \n",
            "[[-0.5525446   2.740004    2.1684823  -1.622999  ]\n",
            " [ 0.6148312   1.5872622   1.5968837  -0.61821735]\n",
            " [ 0.73346364  0.2276063   1.987133    0.60149515]\n",
            " [ 0.5785128   0.08272111  3.0254755  -0.34089282]\n",
            " [ 0.86048615  2.200085    0.31724226 -0.10460893]]\n",
            "\n",
            "Test 5: CUDA result = \n",
            "[[-1.3445698   0.17822582 -0.12659752 -1.3190229 ]\n",
            " [-2.7412527   1.8426757   2.7952137  -3.1676211 ]\n",
            " [-1.1641213  -0.60502625 -1.134767   -1.2530384 ]\n",
            " [-1.3369844   0.40297836 -0.41447634 -2.9693851 ]\n",
            " [-2.2287514  -0.3201996   0.303913   -1.972415  ]],\n",
            " PyTorch result = \n",
            "[[-1.3445698   0.17822582 -0.12659764 -1.3190229 ]\n",
            " [-2.7412527   1.8426759   2.7952137  -3.1676211 ]\n",
            " [-1.1641213  -0.60502625 -1.134767   -1.2530384 ]\n",
            " [-1.3369844   0.40297836 -0.41447628 -2.9693851 ]\n",
            " [-2.2287514  -0.32019955  0.303913   -1.972415  ]]\n",
            "\n",
            "Test 6: CUDA result = \n",
            "[[ 0.2646221  -0.66641957 -2.8590398  -0.2824452 ]\n",
            " [-2.005148   -0.46276945  0.64456     3.9848766 ]\n",
            " [ 0.8198917  -2.6225808  -3.207941   -0.43629646]\n",
            " [-0.95098627  1.313284   -1.2319291   1.5134103 ]\n",
            " [-2.0460372  -2.1720006  -0.17320228  2.8029258 ]],\n",
            " PyTorch result = \n",
            "[[ 0.2646221  -0.6664196  -2.8590398  -0.2824452 ]\n",
            " [-2.005148   -0.46276945  0.64456     3.9848766 ]\n",
            " [ 0.8198917  -2.6225808  -3.207941   -0.43629646]\n",
            " [-0.95098627  1.313284   -1.2319292   1.5134103 ]\n",
            " [-2.0460372  -2.1720006  -0.17320228  2.8029258 ]]\n",
            "\n",
            "Test 7: CUDA result = \n",
            "[[ 0.9804834   0.4037543  -0.27717718  1.6898711 ]\n",
            " [ 4.5007353  -3.5397854  -3.0073507  -1.3269062 ]\n",
            " [ 1.1550888  -1.0736908  -1.6851966  -0.4646331 ]\n",
            " [ 5.8105154  -2.259136   -1.3371716  -0.77533853]\n",
            " [ 1.5890827  -2.4269173  -2.8278434   1.2177548 ]],\n",
            " PyTorch result = \n",
            "[[ 0.9804833   0.40375426 -0.2771772   1.6898711 ]\n",
            " [ 4.5007353  -3.5397851  -3.007351   -1.3269062 ]\n",
            " [ 1.1550887  -1.0736908  -1.6851966  -0.4646331 ]\n",
            " [ 5.8105154  -2.2591357  -1.3371718  -0.77533853]\n",
            " [ 1.5890827  -2.4269173  -2.8278437   1.2177548 ]]\n",
            "\n",
            "Test 8: CUDA result = \n",
            "[[ 0.5232297  -0.52303195 -0.81448036  0.8183296 ]\n",
            " [ 0.5262302   0.75156397  0.22085059 -1.1401337 ]\n",
            " [ 0.5913943  -2.4321373  -2.5112605   2.2137494 ]\n",
            " [ 0.63639545  0.06802815 -0.13329792 -1.9343307 ]\n",
            " [ 0.91603875 -3.3833208  -2.0933905  -0.9809538 ]],\n",
            " PyTorch result = \n",
            "[[ 0.5232297  -0.52303195 -0.81448036  0.8183296 ]\n",
            " [ 0.5262302   0.75156397  0.22085059 -1.1401337 ]\n",
            " [ 0.5913943  -2.4321373  -2.5112605   2.2137494 ]\n",
            " [ 0.6363955   0.06802803 -0.13329792 -1.9343307 ]\n",
            " [ 0.91603875 -3.3833208  -2.0933905  -0.9809538 ]]\n",
            "\n",
            "Test 9: CUDA result = \n",
            "[[-0.9782343  -4.0852375  -0.57226396 -0.45206103]\n",
            " [ 6.4606714  -1.6131438   4.15408    -3.6717746 ]\n",
            " [ 3.1571913  -1.1709778   4.192458    0.03302033]\n",
            " [-2.8329024  -1.3781755  -1.8417649   3.1973555 ]\n",
            " [ 1.2949893   0.5028604  -2.239153    0.5284727 ]],\n",
            " PyTorch result = \n",
            "[[-0.9782343  -4.0852375  -0.57226396 -0.45206106]\n",
            " [ 6.4606714  -1.6131438   4.15408    -3.6717746 ]\n",
            " [ 3.1571913  -1.170978    4.192458    0.03302036]\n",
            " [-2.8329024  -1.3781755  -1.841765    3.1973555 ]\n",
            " [ 1.2949893   0.5028604  -2.239153    0.5284727 ]]\n",
            "\n",
            "Test 10: CUDA result = \n",
            "[[-1.1477723  -1.5132792   0.58861214 -1.367421  ]\n",
            " [-1.0234007   1.9110787  -0.8769235   0.03583431]\n",
            " [-1.3118546   0.47215056  0.17220104 -1.0032961 ]\n",
            " [-0.7147447   0.7081254  -0.13148409 -0.9662098 ]\n",
            " [ 2.8408904   2.371325   -2.0562825  -0.6262693 ]],\n",
            " PyTorch result = \n",
            "[[-1.1477722  -1.5132792   0.58861226 -1.367421  ]\n",
            " [-1.0234008   1.9110787  -0.87692344  0.03583443]\n",
            " [-1.3118546   0.47215056  0.1722011  -1.0032961 ]\n",
            " [-0.7147447   0.7081254  -0.13148409 -0.96620977]\n",
            " [ 2.84089     2.371325   -2.0562825  -0.6262693 ]]\n",
            "\n",
            "Test 11: CUDA result = \n",
            "[[-4.7738037  -0.83674     1.7601473   0.96989095]\n",
            " [-1.1874187   1.329178    1.2363944  -1.5912061 ]\n",
            " [-1.3686435  -0.23656166  1.3607025   0.67609715]\n",
            " [-0.7247852   0.09462392  1.4604731   0.16689605]\n",
            " [-0.5880625  -0.7061553   1.9522386   1.0467405 ]],\n",
            " PyTorch result = \n",
            "[[-4.773804   -0.83674     1.7601473   0.969891  ]\n",
            " [-1.1874187   1.3291777   1.2363944  -1.5912061 ]\n",
            " [-1.3686435  -0.23656166  1.3607025   0.6760971 ]\n",
            " [-0.7247852   0.09462392  1.4604732   0.16689605]\n",
            " [-0.5880626  -0.7061553   1.9522386   1.0467405 ]]\n",
            "\n",
            "Test 12: CUDA result = \n",
            "[[ 1.1286569  -0.9558587   0.804726    0.5498278 ]\n",
            " [ 1.0429934   0.07600993  0.3790167   0.02771282]\n",
            " [ 1.2401757   0.05693087  0.66894764  0.02795874]\n",
            " [ 0.39126927  0.28535515 -0.69008285  1.1479572 ]\n",
            " [-0.9574629  -3.0505614  -1.4764574  -0.2803151 ]],\n",
            " PyTorch result = \n",
            "[[ 1.1286569  -0.9558587   0.804726    0.5498278 ]\n",
            " [ 1.0429934   0.07600993  0.3790167   0.02771282]\n",
            " [ 1.2401757   0.05693084  0.66894764  0.02795874]\n",
            " [ 0.39126927  0.2853552  -0.69008285  1.1479572 ]\n",
            " [-0.957463   -3.0505614  -1.4764574  -0.2803151 ]]\n",
            "\n",
            "Test 13: CUDA result = \n",
            "[[ 0.21191883  0.01015139  1.5390522   1.3357644 ]\n",
            " [-1.1143255  -0.01986384  0.63909864 -1.1507065 ]\n",
            " [-0.03711446 -1.9162213   0.14184594  0.02917172]\n",
            " [-2.343198    2.195301    0.16873133 -2.0157094 ]\n",
            " [ 1.673485   -2.2015302   0.800942    3.220633  ]],\n",
            " PyTorch result = \n",
            "[[ 0.21191882  0.01015139  1.5390522   1.3357644 ]\n",
            " [-1.1143255  -0.01986384  0.63909864 -1.1507065 ]\n",
            " [-0.03711446 -1.9162213   0.14184594  0.02917171]\n",
            " [-2.343198    2.195301    0.16873133 -2.0157094 ]\n",
            " [ 1.673485   -2.2015302   0.800942    3.2206333 ]]\n",
            "\n",
            "Test 14: CUDA result = \n",
            "[[-2.118462    0.07852328 -0.5924832  -0.13952509]\n",
            " [-3.0089767  -1.5447252  -2.055884    1.2786144 ]\n",
            " [-0.38663208  0.45229006  1.0206761  -1.7131188 ]\n",
            " [-1.3187096  -1.7369082  -0.49772972 -0.013181  ]\n",
            " [-1.718653   -0.88251483 -1.0802143  -0.06916184]],\n",
            " PyTorch result = \n",
            "[[-2.118462    0.07852322 -0.5924832  -0.13952509]\n",
            " [-3.0089765  -1.5447252  -2.055884    1.2786144 ]\n",
            " [-0.38663197  0.45229006  1.0206761  -1.7131188 ]\n",
            " [-1.3187096  -1.7369082  -0.49772984 -0.013181  ]\n",
            " [-1.718653   -0.88251483 -1.0802143  -0.06916186]]\n",
            "\n",
            "Test 15: CUDA result = \n",
            "[[ 1.9920517   3.1501484   1.0177488  -1.4366732 ]\n",
            " [ 1.2094711   0.83377266  2.2219017  -2.307254  ]\n",
            " [ 0.07655656  1.9507003   1.9880204  -1.7669955 ]\n",
            " [ 1.5448866   1.4074545   2.3148766  -2.593847  ]\n",
            " [ 1.9178584  -0.297239    0.01839888  0.1247673 ]],\n",
            " PyTorch result = \n",
            "[[ 1.9920517   3.1501484   1.0177488  -1.436673  ]\n",
            " [ 1.2094711   0.83377266  2.2219017  -2.307254  ]\n",
            " [ 0.07655656  1.9507003   1.9880204  -1.7669955 ]\n",
            " [ 1.5448866   1.4074545   2.3148766  -2.5938468 ]\n",
            " [ 1.9178584  -0.297239    0.01839876  0.1247673 ]]\n",
            "\n",
            "Test 16: CUDA result = \n",
            "[[ 2.478464   -1.3845997   1.5838633   0.38036206]\n",
            " [ 1.0079727  -1.2976911  -0.13439763 -0.580667  ]\n",
            " [ 4.355307   -1.4152081   3.7832065   0.6331228 ]\n",
            " [ 1.941849    0.4482777   1.6314702   3.8760169 ]\n",
            " [ 2.522922    0.15605402  2.1454384   0.41523585]],\n",
            " PyTorch result = \n",
            "[[ 2.478464   -1.3845997   1.5838633   0.3803621 ]\n",
            " [ 1.0079727  -1.2976911  -0.13439763 -0.580667  ]\n",
            " [ 4.3553066  -1.4152081   3.783206    0.6331228 ]\n",
            " [ 1.9418488   0.4482777   1.63147     3.8760166 ]\n",
            " [ 2.522922    0.15605402  2.1454382   0.41523585]]\n",
            "\n",
            "Test 17: CUDA result = \n",
            "[[ 1.2860689  -3.318973   -1.0804017  -2.8736823 ]\n",
            " [ 1.324765   -1.5745802   0.6257028   0.01103272]\n",
            " [ 1.0197489  -2.1057649  -0.762393   -2.0708606 ]\n",
            " [ 0.7857556  -2.56528    -2.1875153  -3.9304824 ]\n",
            " [ 1.7154318  -2.4815168   1.4964888   0.5106019 ]],\n",
            " PyTorch result = \n",
            "[[ 1.2860689  -3.318973   -1.0804017  -2.8736825 ]\n",
            " [ 1.324765   -1.5745802   0.6257028   0.01103271]\n",
            " [ 1.0197489  -2.1057649  -0.7623929  -2.0708606 ]\n",
            " [ 0.7857556  -2.56528    -2.1875153  -3.9304824 ]\n",
            " [ 1.7154318  -2.4815168   1.4964888   0.5106019 ]]\n",
            "\n",
            "Test 18: CUDA result = \n",
            "[[ 3.3468957e+00 -8.9403009e-01  8.5461140e-04  3.4084845e+00]\n",
            " [-1.8654324e+00 -9.4759089e-01 -2.1460388e+00  6.2651479e-01]\n",
            " [ 1.6017320e+00 -1.6465621e+00  1.4706031e+00  9.8306012e-01]\n",
            " [ 2.3856962e+00 -1.3169771e+00  2.7164159e+00  2.3820460e+00]\n",
            " [ 2.1600208e+00 -6.3379568e-01  3.2647920e-01  3.6114874e+00]],\n",
            " PyTorch result = \n",
            "[[ 3.3468957e+00 -8.9403009e-01  8.5461140e-04  3.4084845e+00]\n",
            " [-1.8654324e+00 -9.4759089e-01 -2.1460388e+00  6.2651467e-01]\n",
            " [ 1.6017320e+00 -1.6465621e+00  1.4706029e+00  9.8306012e-01]\n",
            " [ 2.3856964e+00 -1.3169771e+00  2.7164159e+00  2.3820457e+00]\n",
            " [ 2.1600211e+00 -6.3379568e-01  3.2647943e-01  3.6114874e+00]]\n",
            "\n",
            "Test 19: CUDA result = \n",
            "[[ 1.3076358   0.07995474 -0.74742544  1.5633426 ]\n",
            " [-0.21182436 -0.09647518  0.35776055  3.5894823 ]\n",
            " [-0.02745968 -0.9490474  -1.345518    1.5497091 ]\n",
            " [ 1.4272494   0.44039178 -1.4915173   0.5558434 ]\n",
            " [-0.27494448  0.13911307 -1.3497927   1.5033702 ]],\n",
            " PyTorch result = \n",
            "[[ 1.3076358   0.07995486 -0.7474255   1.5633426 ]\n",
            " [-0.2118243  -0.09647512  0.35776055  3.5894823 ]\n",
            " [-0.02745968 -0.9490474  -1.345518    1.5497091 ]\n",
            " [ 1.4272494   0.4403919  -1.4915172   0.5558436 ]\n",
            " [-0.27494448  0.13911307 -1.3497927   1.5033702 ]]\n",
            "\n",
            "Test 20: CUDA result = \n",
            "[[ 2.4429379   2.7809916  -3.2974863   3.564363  ]\n",
            " [ 4.0287933   0.7165668  -1.1485777   5.6766553 ]\n",
            " [ 0.17325974  0.97135156  0.6775166  -4.8196993 ]\n",
            " [ 1.6873713   0.8680936  -2.183915    0.45358962]\n",
            " [ 1.2628931   0.41854113 -1.5619502  -1.0858113 ]],\n",
            " PyTorch result = \n",
            "[[ 2.4429379   2.7809916  -3.2974863   3.564363  ]\n",
            " [ 4.0287933   0.7165668  -1.1485777   5.6766553 ]\n",
            " [ 0.17325974  0.97135156  0.6775166  -4.8197    ]\n",
            " [ 1.6873713   0.8680936  -2.183915    0.45358968]\n",
            " [ 1.2628931   0.418541   -1.5619502  -1.0858113 ]]\n",
            "\n",
            "Test 21: CUDA result = \n",
            "[[ 4.5891166  -2.9170585   4.2468653   0.25239122]\n",
            " [ 2.9801214  -1.9188323   3.452402    0.8438678 ]\n",
            " [-2.0553746   1.5390671  -0.37282562  2.1058965 ]\n",
            " [ 3.3825843  -3.230396    2.7802954  -0.10537514]\n",
            " [ 1.704971    1.1504139   2.9907498   2.1450381 ]],\n",
            " PyTorch result = \n",
            "[[ 4.5891166  -2.9170585   4.2468653   0.2523912 ]\n",
            " [ 2.9801214  -1.9188323   3.452402    0.8438678 ]\n",
            " [-2.0553744   1.5390671  -0.37282562  2.1058967 ]\n",
            " [ 3.3825843  -3.230396    2.7802954  -0.10537508]\n",
            " [ 1.704971    1.1504139   2.9907498   2.1450381 ]]\n",
            "\n",
            "Test 22: CUDA result = \n",
            "[[ 3.4360914  -1.2613721   1.0257713  -0.4632002 ]\n",
            " [-0.37454534  2.1085336   0.09405673  0.5840741 ]\n",
            " [ 2.1516142   2.3606653  -0.04967049  1.0319978 ]\n",
            " [-0.17842245  1.4096766   0.9403082  -0.39677298]\n",
            " [ 1.494677   -2.5396433   0.6506028  -0.42612952]],\n",
            " PyTorch result = \n",
            "[[ 3.4360914  -1.2613721   1.0257713  -0.46320015]\n",
            " [-0.37454534  2.1085336   0.09405673  0.5840741 ]\n",
            " [ 2.1516142   2.3606653  -0.04967049  1.0319978 ]\n",
            " [-0.17842245  1.4096766   0.9403082  -0.39677304]\n",
            " [ 1.494677   -2.5396433   0.6506028  -0.42612952]]\n",
            "\n",
            "Test 23: CUDA result = \n",
            "[[-0.88340867  2.2073236  -0.2882719   0.56660193]\n",
            " [-1.747536    1.5995184   0.05616568  0.6600222 ]\n",
            " [-0.50443363  1.9228934   0.13819845 -0.11207622]\n",
            " [-1.3101608   2.4321527  -1.4587272   2.8316593 ]\n",
            " [-2.1777341   1.726391    0.32821834  0.08070767]],\n",
            " PyTorch result = \n",
            "[[-0.8834087   2.2073236  -0.2882719   0.56660193]\n",
            " [-1.747536    1.5995184   0.05616568  0.6600222 ]\n",
            " [-0.50443363  1.9228934   0.13819845 -0.11207616]\n",
            " [-1.3101609   2.4321527  -1.4587272   2.8316593 ]\n",
            " [-2.1777341   1.726391    0.32821834  0.08070767]]\n",
            "\n",
            "Test 24: CUDA result = \n",
            "[[ 1.0411242  -0.65965676  2.4609597   1.6257901 ]\n",
            " [-1.1426986   0.2578761   2.7892044   2.9803784 ]\n",
            " [ 1.1221275  -0.8255897  -0.86691695  0.22562256]\n",
            " [ 2.44636    -1.1562382   0.46407261  0.5049407 ]\n",
            " [ 0.18881273  0.05767214  6.721381    4.4015455 ]],\n",
            " PyTorch result = \n",
            "[[ 1.0411242  -0.65965676  2.4609597   1.6257901 ]\n",
            " [-1.1426986   0.2578761   2.7892044   2.9803784 ]\n",
            " [ 1.1221275  -0.8255897  -0.86691695  0.2256226 ]\n",
            " [ 2.44636    -1.1562382   0.4640726   0.5049406 ]\n",
            " [ 0.18881285  0.05767208  6.721381    4.401545  ]]\n",
            "\n",
            "Test 25: CUDA result = \n",
            "[[ 0.57230586  2.406444   -2.461462    1.1705179 ]\n",
            " [ 0.88668376  1.0333414   0.62499726  0.7525903 ]\n",
            " [-0.51845646 -2.0258474  -0.74576974 -1.5961471 ]\n",
            " [ 0.25171816  1.7556635  -3.035892    0.34477466]\n",
            " [ 0.88098353  2.1453917  -2.2917285  -0.9320195 ]],\n",
            " PyTorch result = \n",
            "[[ 0.57230586  2.406444   -2.461462    1.1705179 ]\n",
            " [ 0.8866838   1.0333414   0.62499726  0.7525903 ]\n",
            " [-0.51845646 -2.0258474  -0.74576974 -1.5961471 ]\n",
            " [ 0.25171816  1.7556635  -3.035892    0.34477466]\n",
            " [ 0.8809836   2.1453917  -2.2917285  -0.9320195 ]]\n",
            "\n",
            "Test 26: CUDA result = \n",
            "[[ 1.2841259  -1.5535245   5.0197005   0.29167774]\n",
            " [-1.2003477   1.2548842   1.4695691   1.0363063 ]\n",
            " [-0.7827006   0.79858494  2.182178   -0.45056367]\n",
            " [ 0.67229605 -0.17155099  2.3962038  -0.38705456]\n",
            " [ 0.02263767  0.7656583   0.8753382   0.23098935]],\n",
            " PyTorch result = \n",
            "[[ 1.2841259  -1.5535245   5.0197005   0.29167777]\n",
            " [-1.2003477   1.2548842   1.4695691   1.0363063 ]\n",
            " [-0.7827006   0.79858494  2.182178   -0.45056364]\n",
            " [ 0.67229605 -0.17155099  2.3962035  -0.3870546 ]\n",
            " [ 0.02263767  0.7656583   0.8753381   0.23098935]]\n",
            "\n",
            "Test 27: CUDA result = \n",
            "[[ 0.5810815   0.22760674 -1.1403947   0.8402971 ]\n",
            " [ 2.0350971  -1.9915924   1.2948151  -1.630838  ]\n",
            " [ 0.23665443  0.95902485  0.34017178  3.0482593 ]\n",
            " [ 0.1324377   1.6130167   0.37067682  7.087309  ]\n",
            " [ 2.0792854  -1.6722567   0.73732173  1.3051555 ]],\n",
            " PyTorch result = \n",
            "[[ 0.5810815   0.22760677 -1.1403944   0.84029716]\n",
            " [ 2.0350971  -1.9915924   1.2948153  -1.630838  ]\n",
            " [ 0.23665443  0.9590249   0.34017178  3.0482593 ]\n",
            " [ 0.13243765  1.6130167   0.3706768   7.087309  ]\n",
            " [ 2.0792854  -1.6722567   0.7373218   1.3051555 ]]\n",
            "\n",
            "Test 28: CUDA result = \n",
            "[[-3.0942032  -2.2388225   0.85756946  2.2123392 ]\n",
            " [-2.3262289  -2.0336938  -1.0822067   3.533525  ]\n",
            " [-1.9175498  -1.912075   -1.469101    3.7203674 ]\n",
            " [-2.9002209  -2.3025198  -0.9677428   3.5059018 ]\n",
            " [ 2.2318318  -1.4346443  -3.4855042   3.1294212 ]],\n",
            " PyTorch result = \n",
            "[[-3.0942032  -2.2388225   0.85756934  2.2123392 ]\n",
            " [-2.3262289  -2.0336938  -1.0822067   3.533525  ]\n",
            " [-1.91755    -1.912075   -1.469101    3.7203674 ]\n",
            " [-2.9002209  -2.3025198  -0.9677428   3.5059018 ]\n",
            " [ 2.2318318  -1.4346443  -3.4855042   3.1294212 ]]\n",
            "\n",
            "Test 29: CUDA result = \n",
            "[[-0.18601608  1.1525605   0.11230081 -2.483907  ]\n",
            " [-2.3654218  -1.2278513   0.9614058  -2.7554278 ]\n",
            " [ 0.93597746  0.5217599   2.483756   -1.0939126 ]\n",
            " [-1.4178283   3.2239618  -1.187118   -3.2918906 ]\n",
            " [-5.1063957   2.671043   -1.3308666  -4.30591   ]],\n",
            " PyTorch result = \n",
            "[[-0.18601608  1.1525605   0.11230075 -2.483907  ]\n",
            " [-2.3654218  -1.2278513   0.9614058  -2.7554278 ]\n",
            " [ 0.93597746  0.52175987  2.483756   -1.0939126 ]\n",
            " [-1.4178283   3.2239618  -1.187118   -3.2918906 ]\n",
            " [-5.1063957   2.671043   -1.3308666  -4.30591   ]]\n",
            "\n",
            "Test 30: CUDA result = \n",
            "[[ 1.3623409   0.10032898 -1.1023903   1.8169858 ]\n",
            " [ 0.9327539  -1.2942233  -1.4482757   0.7657248 ]\n",
            " [-1.3282037  -0.02776653  0.7498177   1.5626601 ]\n",
            " [ 0.5525598  -0.5823007  -0.31325087  1.1901877 ]\n",
            " [-0.7596055   0.79385155 -0.16643018  2.3295698 ]],\n",
            " PyTorch result = \n",
            "[[ 1.3623409   0.10032898 -1.1023902   1.8169858 ]\n",
            " [ 0.9327539  -1.2942233  -1.4482758   0.76572484]\n",
            " [-1.3282038  -0.02776659  0.7498177   1.56266   ]\n",
            " [ 0.55255985 -0.58230066 -0.31325087  1.1901877 ]\n",
            " [-0.75960547  0.79385155 -0.16643015  2.3295698 ]]\n",
            "\n",
            "Test 31: CUDA result = \n",
            "[[-1.1257334   1.6055741   1.2211424  -0.75221443]\n",
            " [ 2.9649136   1.4270996  -1.6257783  -1.5443532 ]\n",
            " [-0.08242831  1.4230336  -0.9608053  -1.3206704 ]\n",
            " [-1.0106997  -0.80206954  2.4843054  -1.5159838 ]\n",
            " [-1.2443328  -0.04367262  2.7680001  -1.1257436 ]],\n",
            " PyTorch result = \n",
            "[[-1.1257334   1.6055741   1.2211424  -0.7522144 ]\n",
            " [ 2.9649136   1.4270996  -1.6257786  -1.5443532 ]\n",
            " [-0.08242831  1.4230336  -0.9608053  -1.3206704 ]\n",
            " [-1.0106997  -0.8020694   2.4843051  -1.5159838 ]\n",
            " [-1.2443328  -0.04367262  2.7680001  -1.1257436 ]]\n",
            "\n",
            "Test 32: CUDA result = \n",
            "[[ 1.7665195  -0.37577575  2.0008717  -1.6182418 ]\n",
            " [-0.10146056  0.07997695  2.4040537  -2.9256673 ]\n",
            " [-1.3841155   0.7731404  -0.48975813 -1.2928259 ]\n",
            " [-0.18110242  0.23066022 -0.1128493  -1.4981304 ]\n",
            " [-1.1276408   0.78023535 -1.1399908  -0.6437341 ]],\n",
            " PyTorch result = \n",
            "[[ 1.7665195  -0.37577575  2.0008717  -1.6182418 ]\n",
            " [-0.10146052  0.07997695  2.4040537  -2.9256673 ]\n",
            " [-1.3841155   0.7731404  -0.4897581  -1.2928259 ]\n",
            " [-0.18110242  0.23066022 -0.11284929 -1.4981304 ]\n",
            " [-1.1276408   0.78023535 -1.1399908  -0.64373416]]\n",
            "\n",
            "Test 33: CUDA result = \n",
            "[[ 2.153162    1.0330069   0.71223724  0.05655766]\n",
            " [ 5.0040207   1.7739012  -0.4394009   2.732053  ]\n",
            " [-0.84613574  0.7385794   2.0698104  -2.0002108 ]\n",
            " [ 2.1099675   2.598815    1.2067804   0.8724052 ]\n",
            " [ 1.8740814   2.6666608   1.3404455   1.1691889 ]],\n",
            " PyTorch result = \n",
            "[[ 2.153162    1.0330068   0.71223724  0.05655766]\n",
            " [ 5.0040207   1.7739012  -0.4394008   2.7320533 ]\n",
            " [-0.8461355   0.73857945  2.0698104  -2.0002108 ]\n",
            " [ 2.1099672   2.598815    1.2067804   0.8724052 ]\n",
            " [ 1.8740814   2.6666608   1.3404455   1.1691889 ]]\n",
            "\n",
            "Test 34: CUDA result = \n",
            "[[-3.9221103  -1.1361525   0.9634565   0.76904255]\n",
            " [-4.037114   -0.06589746  1.639765    0.8120491 ]\n",
            " [-3.1270955   1.1859515   3.186997    1.2330344 ]\n",
            " [-2.8921046   0.7061336   2.863948    1.2177854 ]\n",
            " [ 0.3906372   0.8817338   1.3102565   0.77435017]],\n",
            " PyTorch result = \n",
            "[[-3.9221106  -1.1361523   0.96345663  0.7690425 ]\n",
            " [-4.037114   -0.06589746  1.639765    0.81204915]\n",
            " [-3.1270955   1.1859515   3.186997    1.2330344 ]\n",
            " [-2.8921046   0.7061336   2.863948    1.2177854 ]\n",
            " [ 0.39063722  0.8817338   1.3102565   0.77435017]]\n",
            "\n",
            "Test 35: CUDA result = \n",
            "[[ 0.77651614 -0.2940508  -2.2496254  -0.42188594]\n",
            " [-0.01467159 -0.8660106  -0.02464557 -0.9317074 ]\n",
            " [-0.15228456 -1.0311731  -0.0131585  -2.2518423 ]\n",
            " [-0.71805096 -0.00704844  2.1366801  -1.1775647 ]\n",
            " [ 0.6015742   0.25804704 -1.0943372   1.4748559 ]],\n",
            " PyTorch result = \n",
            "[[ 0.77651614 -0.2940508  -2.2496254  -0.42188594]\n",
            " [-0.01467162 -0.86601055 -0.02464557 -0.9317074 ]\n",
            " [-0.15228459 -1.0311731  -0.01315856 -2.2518423 ]\n",
            " [-0.71805096 -0.0070485   2.1366801  -1.1775647 ]\n",
            " [ 0.6015741   0.258047   -1.0943372   1.4748559 ]]\n",
            "\n",
            "Test 36: CUDA result = \n",
            "[[ 0.99052477  0.19027281  0.7265674  -1.1420454 ]\n",
            " [ 1.5404404   0.8015423  -1.4714499  -2.3269525 ]\n",
            " [-4.424988    1.0442194   0.94211096 -3.1289325 ]\n",
            " [-1.9080333   0.9331111   1.2659112  -2.3463073 ]\n",
            " [ 2.731299   -1.772401    1.6296852   1.4573432 ]],\n",
            " PyTorch result = \n",
            "[[ 0.99052477  0.19027281  0.7265674  -1.1420454 ]\n",
            " [ 1.5404404   0.8015423  -1.4714499  -2.3269525 ]\n",
            " [-4.424988    1.0442194   0.94211096 -3.128932  ]\n",
            " [-1.9080333   0.9331112   1.2659112  -2.3463073 ]\n",
            " [ 2.731299   -1.772401    1.6296852   1.4573432 ]]\n",
            "\n",
            "Test 37: CUDA result = \n",
            "[[ 2.8211777   0.02933669 -0.9375988  -1.4531872 ]\n",
            " [-1.3479288   1.3396573   6.258533    0.9907173 ]\n",
            " [ 2.6211185  -0.5488945  -0.5578749  -1.4981991 ]\n",
            " [ 1.2736676  -1.3176677   0.06110013  2.0601425 ]\n",
            " [ 1.0863879   0.24800372  1.4960539   0.48362368]],\n",
            " PyTorch result = \n",
            "[[ 2.8211777   0.02933663 -0.93759894 -1.4531871 ]\n",
            " [-1.3479288   1.3396573   6.258533    0.99071735]\n",
            " [ 2.6211185  -0.5488945  -0.55787504 -1.498199  ]\n",
            " [ 1.2736677  -1.3176677   0.06110016  2.0601425 ]\n",
            " [ 1.0863879   0.24800378  1.496054    0.48362365]]\n",
            "\n",
            "Test 38: CUDA result = \n",
            "[[ 0.45839775 -0.61836344  1.0412965   0.1215288 ]\n",
            " [ 0.74959826 -0.4624982   0.98204494  0.4633916 ]\n",
            " [-3.0072722   0.21442883 -0.12547356 -1.8422189 ]\n",
            " [-0.03123516 -0.8208026   0.11233431 -0.0985153 ]\n",
            " [-1.0450928   0.01290849  0.22237602 -0.48003525]],\n",
            " PyTorch result = \n",
            "[[ 0.45839775 -0.61836344  1.0412965   0.1215288 ]\n",
            " [ 0.74959826 -0.4624982   0.9820449   0.4633916 ]\n",
            " [-3.0072722   0.21442886 -0.12547362 -1.8422189 ]\n",
            " [-0.03123516 -0.8208026   0.11233431 -0.0985153 ]\n",
            " [-1.0450928   0.01290848  0.22237602 -0.48003525]]\n",
            "\n",
            "Test 39: CUDA result = \n",
            "[[ 0.9498857  -0.35042074 -1.2114433  -1.1906605 ]\n",
            " [ 0.9556088   0.6106131   1.1394275   0.73473006]\n",
            " [ 0.8164068  -0.627396   -1.0163257  -0.88101554]\n",
            " [ 0.6769762  -0.643843   -1.523735   -1.84249   ]\n",
            " [ 1.0479964   1.6397806   0.35366836 -1.391736  ]],\n",
            " PyTorch result = \n",
            "[[ 0.9498857  -0.35042074 -1.2114433  -1.1906605 ]\n",
            " [ 0.9556088   0.61061305  1.1394275   0.73473006]\n",
            " [ 0.8164068  -0.6273959  -1.0163257  -0.88101554]\n",
            " [ 0.6769762  -0.6438429  -1.523735   -1.84249   ]\n",
            " [ 1.0479964   1.6397806   0.35366836 -1.3917359 ]]\n",
            "\n",
            "Test 40: CUDA result = \n",
            "[[ 0.24216652 -0.08438167 -3.4236465   1.0315163 ]\n",
            " [ 2.528344    0.95579773  2.8097892  -2.4672608 ]\n",
            " [ 0.8855346  -2.1986966  -1.7311777  -1.2322061 ]\n",
            " [-0.5568696  -0.8792539  -5.5713162   2.0561767 ]\n",
            " [ 0.9958687   1.5309484  -1.238565    0.6261189 ]],\n",
            " PyTorch result = \n",
            "[[ 0.24216652 -0.08438167 -3.4236465   1.0315163 ]\n",
            " [ 2.528344    0.95579773  2.8097892  -2.467261  ]\n",
            " [ 0.8855345  -2.1986966  -1.7311777  -1.2322061 ]\n",
            " [-0.5568696  -0.8792539  -5.571316    2.0561767 ]\n",
            " [ 0.9958687   1.5309484  -1.238565    0.62611896]]\n",
            "\n",
            "Test 41: CUDA result = \n",
            "[[-0.6891766  -2.6476316   1.6123188  -1.298457  ]\n",
            " [-1.8216054  -1.6117458  -1.5823846   2.562444  ]\n",
            " [-1.1353314  -0.47921604  0.592464   -0.39641264]\n",
            " [ 2.2069411  -0.09848547  3.9386387  -3.1411483 ]\n",
            " [ 1.5806322   0.3556913   1.4534389   0.09309989]],\n",
            " PyTorch result = \n",
            "[[-0.6891767  -2.6476316   1.6123188  -1.2984569 ]\n",
            " [-1.8216054  -1.6117458  -1.5823846   2.562444  ]\n",
            " [-1.1353314  -0.47921604  0.59246397 -0.39641264]\n",
            " [ 2.206941   -0.09848547  3.9386387  -3.1411483 ]\n",
            " [ 1.5806322   0.3556913   1.4534388   0.09309989]]\n",
            "\n",
            "Test 42: CUDA result = \n",
            "[[ 0.96412456  3.668403    2.3296764   1.0486943 ]\n",
            " [ 1.0339023   2.4349952  -2.1438735   0.9821665 ]\n",
            " [ 2.0263247  -2.925378    0.9045998   2.2704473 ]\n",
            " [ 1.0573201  -0.3718817  -1.0722082   1.7509445 ]\n",
            " [ 1.0991098  -3.4780705   2.3308265   2.7714033 ]],\n",
            " PyTorch result = \n",
            "[[ 0.96412456  3.668403    2.3296764   1.0486943 ]\n",
            " [ 1.0339023   2.4349952  -2.1438732   0.9821665 ]\n",
            " [ 2.0263247  -2.925378    0.9045998   2.2704473 ]\n",
            " [ 1.0573201  -0.3718817  -1.0722082   1.7509445 ]\n",
            " [ 1.0991096  -3.4780705   2.3308265   2.7714033 ]]\n",
            "\n",
            "Test 43: CUDA result = \n",
            "[[-0.27853888 -2.6496506  -0.3995502  -1.4182425 ]\n",
            " [ 1.6825354  -0.41017926 -0.13669753 -0.68006927]\n",
            " [ 0.17283148 -1.8687519  -0.6203878  -1.2301036 ]\n",
            " [ 0.56664664  0.34922534 -2.4158225  -1.5635457 ]\n",
            " [ 1.3723869   0.25124723 -1.2280083  -1.3485253 ]],\n",
            " PyTorch result = \n",
            "[[-0.27853876 -2.6496506  -0.39955008 -1.4182425 ]\n",
            " [ 1.6825354  -0.41017926 -0.13669753 -0.68006927]\n",
            " [ 0.17283148 -1.8687519  -0.6203878  -1.2301036 ]\n",
            " [ 0.56664664  0.3492254  -2.4158225  -1.5635457 ]\n",
            " [ 1.3723869   0.25124723 -1.2280083  -1.3485253 ]]\n",
            "\n",
            "Test 44: CUDA result = \n",
            "[[-5.2630315  -1.8386891   2.7233117   1.2239835 ]\n",
            " [-1.849776   -1.3148284   3.3121402  -0.37555856]\n",
            " [-1.9411492   0.02369285 -0.13478328  0.7382537 ]\n",
            " [-2.426577   -0.90282935  2.4496174   0.8115008 ]\n",
            " [-2.2025504  -0.26059973  1.3012655   1.552422  ]],\n",
            " PyTorch result = \n",
            "[[-5.2630315  -1.8386891   2.7233114   1.2239835 ]\n",
            " [-1.849776   -1.3148284   3.31214    -0.37555856]\n",
            " [-1.9411492   0.02369285 -0.13478324  0.7382537 ]\n",
            " [-2.426577   -0.90282935  2.4496174   0.8115008 ]\n",
            " [-2.2025504  -0.26059973  1.3012657   1.552422  ]]\n",
            "\n",
            "Test 45: CUDA result = \n",
            "[[-1.3350046  -1.7622052   0.3356038   0.02495563]\n",
            " [-2.3928561  -1.601119    1.1569068  -0.8723006 ]\n",
            " [-1.1036414  -1.7948934  -0.76479703 -0.0863632 ]\n",
            " [-0.55762684 -1.1389277  -0.15079224  0.96045685]\n",
            " [-3.238928   -0.283859    1.5994737  -1.2820868 ]],\n",
            " PyTorch result = \n",
            "[[-1.3350046  -1.7622052   0.3356038   0.02495563]\n",
            " [-2.3928561  -1.601119    1.1569068  -0.8723006 ]\n",
            " [-1.1036415  -1.7948934  -0.76479703 -0.0863632 ]\n",
            " [-0.55762684 -1.1389277  -0.15079227  0.96045685]\n",
            " [-3.238928   -0.28385913  1.5994737  -1.2820868 ]]\n",
            "\n",
            "Test 46: CUDA result = \n",
            "[[ 0.7696137  -1.910619    2.3996644   1.5912476 ]\n",
            " [-0.45544547 -1.3347825   1.1662556  -0.4279642 ]\n",
            " [ 0.88097715 -2.3964083  -1.9522045   0.12249404]\n",
            " [-0.13007805 -2.513974   -1.5228413  -0.05259031]\n",
            " [ 0.32449374 -2.3828251  -1.8988632  -0.16678274]],\n",
            " PyTorch result = \n",
            "[[ 0.7696137  -1.910619    2.3996644   1.5912476 ]\n",
            " [-0.45544547 -1.3347826   1.1662556  -0.42796427]\n",
            " [ 0.88097715 -2.3964083  -1.9522045   0.12249404]\n",
            " [-0.13007805 -2.513974   -1.5228413  -0.05259031]\n",
            " [ 0.32449377 -2.3828251  -1.8988632  -0.16678274]]\n",
            "\n",
            "Test 47: CUDA result = \n",
            "[[-0.57852757 -1.1723888   0.8680904  -0.11291516]\n",
            " [ 1.014777   -2.2034132  -1.5309466   2.4991057 ]\n",
            " [ 2.924133   -1.8369924  -3.5675478   0.6346577 ]\n",
            " [ 2.380016   -4.2470527   0.58848464  1.9076684 ]\n",
            " [-1.0647686  -0.19717604  0.32032812 -0.7781479 ]],\n",
            " PyTorch result = \n",
            "[[-0.57852757 -1.1723889   0.8680904  -0.11291516]\n",
            " [ 1.014777   -2.2034132  -1.5309466   2.4991055 ]\n",
            " [ 2.924133   -1.8369924  -3.5675476   0.6346577 ]\n",
            " [ 2.380016   -4.2470527   0.58848464  1.9076681 ]\n",
            " [-1.0647686  -0.19717604  0.32032812 -0.7781479 ]]\n",
            "\n",
            "Test 48: CUDA result = \n",
            "[[-0.10713419 -0.7589178   1.8797162   2.1178603 ]\n",
            " [-0.61590135  2.049521    2.2466826  -0.8450513 ]\n",
            " [ 1.5064094  -0.72848487 -0.06181824  1.4330528 ]\n",
            " [-0.3931721   0.30294168  3.122554    1.6158657 ]\n",
            " [ 1.0395854   1.1602715   0.2558242  -0.5555591 ]],\n",
            " PyTorch result = \n",
            "[[-0.10713416 -0.7589178   1.8797159   2.1178603 ]\n",
            " [-0.61590135  2.049521    2.2466826  -0.8450513 ]\n",
            " [ 1.5064094  -0.72848487 -0.0618183   1.4330528 ]\n",
            " [-0.39317203  0.3029418   3.122554    1.6158657 ]\n",
            " [ 1.0395854   1.1602715   0.2558242  -0.5555591 ]]\n",
            "\n",
            "Test 49: CUDA result = \n",
            "[[-0.26376975  2.0611317   0.62721026 -2.2147439 ]\n",
            " [ 0.01422501  1.2984879   0.8597672  -0.33153737]\n",
            " [ 1.0175718   2.0789938   1.1351712  -0.99011767]\n",
            " [-0.9252997  -0.19756722  0.6262498   3.4424767 ]\n",
            " [-0.1822002   2.0704482   0.47408003  0.75155085]],\n",
            " PyTorch result = \n",
            "[[-0.26376975  2.0611317   0.62721026 -2.2147439 ]\n",
            " [ 0.01422501  1.2984879   0.8597672  -0.33153737]\n",
            " [ 1.0175718   2.0789938   1.1351712  -0.99011767]\n",
            " [-0.9252997  -0.19756699  0.6262498   3.4424767 ]\n",
            " [-0.1822002   2.0704482   0.47408003  0.75155085]]\n",
            "\n",
            "Test 50: CUDA result = \n",
            "[[-2.3633451  -5.7129717  -1.0583525   6.8867283 ]\n",
            " [ 0.28795195  1.1716813   3.0459414   3.6271791 ]\n",
            " [-0.95922565  0.5371238  -1.4305912   2.4268436 ]\n",
            " [ 2.0322843  -2.3379664   1.9812678   4.3935695 ]\n",
            " [ 3.249726   -1.5107708   0.197371    2.5171828 ]],\n",
            " PyTorch result = \n",
            "[[-2.3633451  -5.7129717  -1.0583524   6.8867283 ]\n",
            " [ 0.28795195  1.1716814   3.0459414   3.6271791 ]\n",
            " [-0.95922565  0.5371239  -1.4305912   2.4268436 ]\n",
            " [ 2.0322843  -2.3379664   1.9812678   4.3935695 ]\n",
            " [ 3.249726   -1.5107708   0.19737099  2.5171828 ]]\n",
            "\n",
            "Test 51: CUDA result = \n",
            "[[-0.44966656  2.8964765   0.54211     0.59783995]\n",
            " [-0.3676683   3.737822   -3.2934887  -0.26303124]\n",
            " [ 0.07715662  4.2399616   3.1721241  -0.19032146]\n",
            " [ 0.5493204   3.069802    0.11055088 -0.70004565]\n",
            " [ 0.7538071   2.9117053   5.2435403  -0.26684052]],\n",
            " PyTorch result = \n",
            "[[-0.44966662  2.8964765   0.54211     0.59783995]\n",
            " [-0.36766827  3.737822   -3.2934887  -0.26303124]\n",
            " [ 0.07715662  4.2399616   3.1721241  -0.19032143]\n",
            " [ 0.5493204   3.0698023   0.11055088 -0.70004565]\n",
            " [ 0.7538071   2.9117055   5.2435403  -0.26684052]]\n",
            "\n",
            "Test 52: CUDA result = \n",
            "[[-0.22972499 -0.10675156  1.4192953   1.0102987 ]\n",
            " [-0.24606702 -2.4716365  -1.0660403   1.2015965 ]\n",
            " [ 0.38769954  0.34231788  1.0989902   0.9047676 ]\n",
            " [ 1.5405438   1.4387162   2.1351492  -0.05377316]\n",
            " [-4.027898   -4.8754916  -1.3938613   3.2667623 ]],\n",
            " PyTorch result = \n",
            "[[-0.22972499 -0.10675156  1.4192953   1.0102987 ]\n",
            " [-0.24606703 -2.4716365  -1.0660405   1.2015965 ]\n",
            " [ 0.38769954  0.34231788  1.0989902   0.9047675 ]\n",
            " [ 1.5405437   1.4387162   2.1351492  -0.05377328]\n",
            " [-4.027898   -4.875491   -1.3938613   3.2667623 ]]\n",
            "\n",
            "Test 53: CUDA result = \n",
            "[[ 6.6816711e-01  1.5328796e+00 -9.1566783e-01 -2.0905858e-01]\n",
            " [ 6.2443531e-01  2.9143518e-01 -1.3008386e+00 -9.1659886e-01]\n",
            " [ 3.8050136e-01 -2.2010940e-01  2.5050044e-02 -2.9756260e-01]\n",
            " [ 4.2983067e-01  6.3498372e-01 -3.7916422e-02 -6.6213608e-03]\n",
            " [-1.2013693e+00 -7.2220230e+00  2.5445914e+00 -1.3105702e+00]],\n",
            " PyTorch result = \n",
            "[[ 6.6816711e-01  1.5328796e+00 -9.1566783e-01 -2.0905858e-01]\n",
            " [ 6.2443531e-01  2.9143518e-01 -1.3008386e+00 -9.1659892e-01]\n",
            " [ 3.8050136e-01 -2.2010940e-01  2.5050044e-02 -2.9756260e-01]\n",
            " [ 4.2983067e-01  6.3498384e-01 -3.7916422e-02 -6.6213608e-03]\n",
            " [-1.2013692e+00 -7.2220230e+00  2.5445914e+00 -1.3105702e+00]]\n",
            "\n",
            "Test 54: CUDA result = \n",
            "[[ 0.50038457 -1.1482805   0.12747967 -1.9082499 ]\n",
            " [ 4.5487      1.9026262   1.4523096   3.7545328 ]\n",
            " [ 2.2970502  -0.50989276  1.1622027   1.9822719 ]\n",
            " [ 3.2465568   0.32963285  0.95680773  0.98174596]\n",
            " [ 5.6428666   1.2413214   2.3453755   6.274456  ]],\n",
            " PyTorch result = \n",
            "[[ 0.50038457 -1.1482805   0.12747967 -1.9082499 ]\n",
            " [ 4.5487003   1.9026262   1.4523096   3.7545328 ]\n",
            " [ 2.2970505  -0.5098927   1.1622027   1.9822719 ]\n",
            " [ 3.2465568   0.32963282  0.95680773  0.98174596]\n",
            " [ 5.6428666   1.2413214   2.3453755   6.2744565 ]]\n",
            "\n",
            "Test 55: CUDA result = \n",
            "[[ 0.7784101   0.574862    0.9420123   1.6430662 ]\n",
            " [ 1.0270671   0.137939    0.4604399  -0.91750836]\n",
            " [ 1.373302    0.09687648  0.7361386  -0.25948238]\n",
            " [ 0.9926799   0.36340863  0.65001553 -0.01472801]\n",
            " [ 0.79839796  0.31671298  0.7411465   0.7137859 ]],\n",
            " PyTorch result = \n",
            "[[ 0.7784101   0.574862    0.9420123   1.6430662 ]\n",
            " [ 1.0270671   0.137939    0.4604399  -0.91750836]\n",
            " [ 1.3733021   0.09687647  0.7361386  -0.25948238]\n",
            " [ 0.9926799   0.36340863  0.65001553 -0.01472801]\n",
            " [ 0.79839796  0.31671298  0.7411465   0.7137859 ]]\n",
            "\n",
            "Test 56: CUDA result = \n",
            "[[ 2.262958   -1.6592022   2.5606081   1.2176397 ]\n",
            " [-1.9574482  -0.28909117 -1.3785722   0.01906559]\n",
            " [-2.169222    0.07088178 -0.8431511   0.00778268]\n",
            " [ 0.07947934 -1.4998977   1.0548625   0.20354961]\n",
            " [-1.921675   -0.5067094  -1.6214287  -0.04351473]],\n",
            " PyTorch result = \n",
            "[[ 2.2629578  -1.6592021   2.5606081   1.2176397 ]\n",
            " [-1.9574482  -0.28909117 -1.3785722   0.0190656 ]\n",
            " [-2.169222    0.07088184 -0.8431511   0.00778268]\n",
            " [ 0.07947922 -1.4998977   1.0548625   0.20354961]\n",
            " [-1.921675   -0.5067094  -1.6214287  -0.04351473]]\n",
            "\n",
            "Test 57: CUDA result = \n",
            "[[ 1.3722391  -1.4676718   0.58984494 -2.7921145 ]\n",
            " [ 0.72121847  0.11561021  1.2902359  -2.0137644 ]\n",
            " [-0.07176319  0.77428603  2.664196   -0.9162328 ]\n",
            " [ 2.6005805  -2.0301158   1.8155886  -2.825223  ]\n",
            " [ 0.4524571  -0.14319918  0.6026207  -2.2414627 ]],\n",
            " PyTorch result = \n",
            "[[ 1.3722391  -1.4676718   0.58984494 -2.7921145 ]\n",
            " [ 0.72121847  0.11561022  1.2902359  -2.0137644 ]\n",
            " [-0.07176319  0.774286    2.664196   -0.9162328 ]\n",
            " [ 2.6005805  -2.0301158   1.8155885  -2.825223  ]\n",
            " [ 0.4524571  -0.14319918  0.6026207  -2.2414627 ]]\n",
            "\n",
            "Test 58: CUDA result = \n",
            "[[-0.00980711  1.2152646  -1.8745941   0.79243565]\n",
            " [ 0.6195184   2.8597326   0.8447393   0.9260841 ]\n",
            " [-3.161889    3.8373194  -0.35946807  1.3491062 ]\n",
            " [-3.1370068   2.6629624  -1.0102289   0.7346235 ]\n",
            " [ 3.293581    2.7213435   2.5041907   0.6709594 ]],\n",
            " PyTorch result = \n",
            "[[-0.00980711  1.2152646  -1.874594    0.79243565]\n",
            " [ 0.6195184   2.8597326   0.8447393   0.9260841 ]\n",
            " [-3.161889    3.8373194  -0.35946807  1.3491062 ]\n",
            " [-3.1370068   2.6629624  -1.0102289   0.7346235 ]\n",
            " [ 3.293581    2.7213438   2.5041907   0.6709595 ]]\n",
            "\n",
            "Test 59: CUDA result = \n",
            "[[ 0.7232916   2.6656773  -0.87588346  1.6155889 ]\n",
            " [ 0.44471592 -0.73733276 -0.4042995   3.1225998 ]\n",
            " [ 0.82996225 -1.115486   -2.3953881   2.2838573 ]\n",
            " [ 0.68324256  0.9826725  -3.2267697   2.8865297 ]\n",
            " [ 0.48639917  0.63893414  0.21593273  2.5172899 ]],\n",
            " PyTorch result = \n",
            "[[ 0.7232916   2.6656773  -0.87588346  1.6155889 ]\n",
            " [ 0.44471592 -0.7373328  -0.4042995   3.1225996 ]\n",
            " [ 0.82996225 -1.115486   -2.3953881   2.2838573 ]\n",
            " [ 0.68324256  0.9826725  -3.2267697   2.8865294 ]\n",
            " [ 0.4863992   0.6389341   0.21593273  2.5172899 ]]\n",
            "\n",
            "Test 60: CUDA result = \n",
            "[[-1.30183    -0.88826525  3.0033345  -1.7511876 ]\n",
            " [-1.9446627  -2.0656068   2.5390172   1.5470152 ]\n",
            " [ 1.7005084  -1.1126146  -0.07848573 -0.7792772 ]\n",
            " [-1.8384235  -1.159694    2.8903413   0.9867104 ]\n",
            " [ 0.7043611  -0.7463802   0.9111704  -0.3303617 ]],\n",
            " PyTorch result = \n",
            "[[-1.30183    -0.88826525  3.0033345  -1.7511877 ]\n",
            " [-1.9446628  -2.0656068   2.5390172   1.5470152 ]\n",
            " [ 1.7005084  -1.1126146  -0.07848573 -0.7792772 ]\n",
            " [-1.8384235  -1.159694    2.8903413   0.9867104 ]\n",
            " [ 0.7043611  -0.7463802   0.9111704  -0.3303617 ]]\n",
            "\n",
            "Test 61: CUDA result = \n",
            "[[ 5.0572314   0.88654876  0.6638362   1.0131803 ]\n",
            " [ 0.92362237 -1.2720613   0.5632939  -0.70084655]\n",
            " [ 0.6694497  -0.82071936 -0.611407   -1.5023587 ]\n",
            " [-1.5027533  -0.7139915   0.3502544  -2.0686297 ]\n",
            " [ 0.89234227 -1.7883047   0.22667193 -0.81079245]],\n",
            " PyTorch result = \n",
            "[[ 5.0572314   0.8865489   0.66383624  1.0131803 ]\n",
            " [ 0.92362237 -1.2720613   0.5632939  -0.70084655]\n",
            " [ 0.6694497  -0.82071936 -0.6114071  -1.5023587 ]\n",
            " [-1.5027533  -0.7139915   0.3502544  -2.0686297 ]\n",
            " [ 0.89234227 -1.7883047   0.22667193 -0.81079245]]\n",
            "\n",
            "Test 62: CUDA result = \n",
            "[[ 0.00748521 -2.052977   -0.6998587  -0.7533593 ]\n",
            " [-0.19380867 -0.80485183  0.24134254 -0.98839754]\n",
            " [ 0.65131927 -1.1929654  -1.4931688  -0.7193794 ]\n",
            " [ 4.1771884  -3.507604   -2.9452477   0.3554141 ]\n",
            " [ 1.2725856   0.44649518 -0.66524035 -0.836517  ]],\n",
            " PyTorch result = \n",
            "[[ 0.00748521 -2.052977   -0.6998587  -0.7533593 ]\n",
            " [-0.19380867 -0.80485183  0.24134254 -0.98839754]\n",
            " [ 0.65131927 -1.1929654  -1.4931688  -0.7193794 ]\n",
            " [ 4.1771884  -3.5076036  -2.9452477   0.3554141 ]\n",
            " [ 1.2725856   0.4464953  -0.6652404  -0.836517  ]]\n",
            "\n",
            "Test 63: CUDA result = \n",
            "[[ 1.4520528   0.05450821  0.42668015  3.1804838 ]\n",
            " [-1.5060058   0.8457527   0.6588838   0.70546305]\n",
            " [-3.5706844   2.1232436  -2.4415646   2.1142812 ]\n",
            " [-4.2405043   1.8172828  -0.27589315 -0.273759  ]\n",
            " [ 0.7819247   0.3814286   0.31320643  1.3156996 ]],\n",
            " PyTorch result = \n",
            "[[ 1.4520528   0.05450821  0.42668015  3.1804838 ]\n",
            " [-1.5060058   0.8457528   0.6588838   0.70546305]\n",
            " [-3.5706844   2.1232436  -2.4415646   2.1142812 ]\n",
            " [-4.2405043   1.8172827  -0.27589315 -0.273759  ]\n",
            " [ 0.7819247   0.3814286   0.31320643  1.3156996 ]]\n",
            "\n",
            "Test 64: CUDA result = \n",
            "[[ 1.6399691   0.692379   -0.5212585  -0.24438035]\n",
            " [ 3.4698548   0.9961823  -1.4837383  -2.4047627 ]\n",
            " [ 2.0195723   1.9665128  -0.47570106 -0.8194568 ]\n",
            " [ 3.9249692   4.0717854   0.37775823 -3.567116  ]\n",
            " [ 0.6888132  -0.9589592   2.1336856   0.52395093]],\n",
            " PyTorch result = \n",
            "[[ 1.6399691   0.6923791  -0.5212585  -0.24438035]\n",
            " [ 3.4698548   0.9961823  -1.4837383  -2.404763  ]\n",
            " [ 2.0195723   1.966513   -0.47570112 -0.8194568 ]\n",
            " [ 3.9249692   4.0717854   0.3777582  -3.5671165 ]\n",
            " [ 0.68881315 -0.9589592   2.1336856   0.52395093]]\n",
            "\n",
            "Test 65: CUDA result = \n",
            "[[-0.18022075 -0.87375116 -3.0272927  -1.9828944 ]\n",
            " [-0.10021625 -0.82299113 -3.092669   -1.3781182 ]\n",
            " [-0.22053444  0.09133872  3.671905   -0.31809902]\n",
            " [-0.18414786  0.05888585  1.6356274  -0.02746166]\n",
            " [-0.06703509 -0.1954627   1.9071019   0.00544921]],\n",
            " PyTorch result = \n",
            "[[-0.18022074 -0.8737512  -3.0272927  -1.9828944 ]\n",
            " [-0.10021627 -0.8229912  -3.092669   -1.3781182 ]\n",
            " [-0.22053446  0.09133872  3.671905   -0.31809902]\n",
            " [-0.18414786  0.05888585  1.6356274  -0.02746166]\n",
            " [-0.06703509 -0.1954627   1.9071019   0.00544922]]\n",
            "\n",
            "Test 66: CUDA result = \n",
            "[[-1.7429265   0.43177634 -1.2494388   3.6551933 ]\n",
            " [-1.8391896  -0.80455685  0.64523506  1.6302959 ]\n",
            " [ 3.7400982   3.834734   -2.9297898   2.98043   ]\n",
            " [-1.5324129   0.09109619  0.18981361  2.3525536 ]\n",
            " [-0.6518358   0.39661336  0.20114541  1.8884244 ]],\n",
            " PyTorch result = \n",
            "[[-1.7429265   0.43177634 -1.2494388   3.6551933 ]\n",
            " [-1.8391894  -0.80455685  0.64523506  1.6302958 ]\n",
            " [ 3.7400985   3.834734   -2.9297898   2.98043   ]\n",
            " [-1.5324129   0.09109616  0.18981361  2.3525538 ]\n",
            " [-0.6518358   0.39661336  0.20114541  1.8884245 ]]\n",
            "\n",
            "Test 67: CUDA result = \n",
            "[[-0.24714112  2.3428748   0.23387265  0.16368283]\n",
            " [ 1.248147   -0.7465677  -0.47689772  0.08422534]\n",
            " [-1.1197407   3.854065   -0.55480194  0.24857286]\n",
            " [-0.39000967  2.1861603  -0.89847267  0.12161864]\n",
            " [-1.4618188   2.8035436  -1.1618942  -0.56804174]],\n",
            " PyTorch result = \n",
            "[[-0.2471411   2.3428748   0.23387265  0.16368283]\n",
            " [ 1.248147   -0.7465675  -0.47689778  0.08422534]\n",
            " [-1.1197407   3.854065   -0.5548018   0.24857286]\n",
            " [-0.39000967  2.1861603  -0.89847267  0.12161864]\n",
            " [-1.4618188   2.8035436  -1.1618942  -0.56804174]]\n",
            "\n",
            "Test 68: CUDA result = \n",
            "[[ 0.23563421 -0.03609268 -1.5917931   0.92991567]\n",
            " [-2.1410127  -1.048458    1.9719291  -0.87948847]\n",
            " [-0.99569905 -0.6630915   2.877213   -0.1723595 ]\n",
            " [-0.31848848 -0.41935092 -0.24790645  0.22363639]\n",
            " [ 1.4675195   0.5227974   2.4132457   2.0212045 ]],\n",
            " PyTorch result = \n",
            "[[ 0.23563421 -0.03609271 -1.5917933   0.92991567]\n",
            " [-2.1410122  -1.048458    1.9719291  -0.87948847]\n",
            " [-0.99569905 -0.6630915   2.877213   -0.1723595 ]\n",
            " [-0.31848848 -0.41935092 -0.24790645  0.22363636]\n",
            " [ 1.4675195   0.5227974   2.4132457   2.0212045 ]]\n",
            "\n",
            "Test 69: CUDA result = \n",
            "[[ 0.3327136   1.0837098  -0.06386092 -1.730535  ]\n",
            " [ 1.4237115   1.1726955  -0.8466395   1.0302724 ]\n",
            " [-0.00632632  0.37748933 -0.36976442 -0.5522016 ]\n",
            " [-1.5877274   0.8331282  -1.256222    0.63021016]\n",
            " [ 0.9686152  -3.5773318   0.41719735  0.80360115]],\n",
            " PyTorch result = \n",
            "[[ 0.3327136   1.0837098  -0.06386092 -1.730535  ]\n",
            " [ 1.4237115   1.1726954  -0.8466395   1.0302722 ]\n",
            " [-0.00632632  0.37748933 -0.36976442 -0.5522016 ]\n",
            " [-1.5877274   0.8331282  -1.256222    0.63021016]\n",
            " [ 0.9686152  -3.5773318   0.41719735  0.80360126]]\n",
            "\n",
            "Test 70: CUDA result = \n",
            "[[ 0.13565552  3.155782   -1.1893728  -1.7600374 ]\n",
            " [ 1.4933796   2.2518778  -0.65065587  0.21915519]\n",
            " [ 4.7243648   1.5223693   1.285643    2.3115706 ]\n",
            " [ 1.9180782   1.1091039  -1.5183508   0.42799956]\n",
            " [-0.34609246  1.9194086  -2.8088193  -1.8108394 ]],\n",
            " PyTorch result = \n",
            "[[ 0.13565552  3.155782   -1.1893728  -1.7600372 ]\n",
            " [ 1.4933796   2.2518778  -0.65065587  0.21915513]\n",
            " [ 4.7243648   1.5223694   1.285643    2.3115706 ]\n",
            " [ 1.9180782   1.1091039  -1.5183508   0.42799956]\n",
            " [-0.34609246  1.9194086  -2.8088193  -1.8108394 ]]\n",
            "\n",
            "Test 71: CUDA result = \n",
            "[[-2.2547257   0.53876275  0.5395966   0.0216811 ]\n",
            " [-1.1838089   3.89774     0.55581     3.755113  ]\n",
            " [-0.7769964   2.2690063   2.09447     2.7757638 ]\n",
            " [-1.6422577   0.6072707   1.971915    0.6761713 ]\n",
            " [ 0.33064127 -1.3811957   2.3973253   0.3796332 ]],\n",
            " PyTorch result = \n",
            "[[-2.2547257   0.53876275  0.5395966   0.0216811 ]\n",
            " [-1.1838089   3.89774     0.55581003  3.7551131 ]\n",
            " [-0.7769963   2.269006    2.09447     2.7757638 ]\n",
            " [-1.6422577   0.6072707   1.971915    0.67617136]\n",
            " [ 0.33064127 -1.3811957   2.3973253   0.37963316]]\n",
            "\n",
            "Test 72: CUDA result = \n",
            "[[ 1.4511722   0.16176325 -0.9301192  -1.946116  ]\n",
            " [ 1.4244374  -0.19414932 -0.8984146  -2.159071  ]\n",
            " [-0.21318099  3.734778   -1.633048    0.38745368]\n",
            " [ 0.6063738   0.28163844  0.05489862 -1.3159637 ]\n",
            " [ 0.39091644 -0.09327674  0.97317046 -1.1479352 ]],\n",
            " PyTorch result = \n",
            "[[ 1.4511722   0.16176331 -0.9301192  -1.946116  ]\n",
            " [ 1.4244374  -0.19414932 -0.8984146  -2.159071  ]\n",
            " [-0.21318099  3.734778   -1.633048    0.38745368]\n",
            " [ 0.6063738   0.28163844  0.05489862 -1.3159637 ]\n",
            " [ 0.3909164  -0.09327674  0.97317046 -1.1479352 ]]\n",
            "\n",
            "Test 73: CUDA result = \n",
            "[[-0.11138065  0.57547593 -1.6364295  -0.644452  ]\n",
            " [ 3.7488317  -3.3937294  -1.2366153  -0.6390457 ]\n",
            " [-0.63166386  1.4066557  -0.59819126 -0.29985347]\n",
            " [ 1.4071014  -1.5440499  -2.4279032  -0.8767286 ]\n",
            " [ 3.3768897  -2.8368235  -2.668458   -1.2005497 ]],\n",
            " PyTorch result = \n",
            "[[-0.11138065  0.57547593 -1.6364295  -0.644452  ]\n",
            " [ 3.7488317  -3.3937292  -1.2366154  -0.63904566]\n",
            " [-0.6316639   1.4066557  -0.59819126 -0.29985344]\n",
            " [ 1.4071014  -1.5440499  -2.427903   -0.87672853]\n",
            " [ 3.3768897  -2.8368235  -2.668458   -1.2005497 ]]\n",
            "\n",
            "Test 74: CUDA result = \n",
            "[[-0.20212029 -0.36539024  0.6392051   1.1701211 ]\n",
            " [ 0.27049965  0.61101437 -0.21834767  0.6137488 ]\n",
            " [-1.3997954   1.6208677   0.9327      1.0714144 ]\n",
            " [-1.1927427   0.584758    1.3964336   0.84136736]\n",
            " [ 0.01621336 -0.7975579   1.1324835   0.093014  ]],\n",
            " PyTorch result = \n",
            "[[-0.20212029 -0.3653903   0.63920516  1.1701211 ]\n",
            " [ 0.27049965  0.61101437 -0.21834767  0.6137488 ]\n",
            " [-1.3997954   1.6208675   0.9327      1.0714144 ]\n",
            " [-1.1927427   0.584758    1.3964336   0.84136736]\n",
            " [ 0.01621337 -0.7975579   1.1324835   0.09301394]]\n",
            "\n",
            "Test 75: CUDA result = \n",
            "[[-2.6196933  -0.53752387  1.9721649  -0.22582722]\n",
            " [-3.638156   -3.3526914  -0.42134583  2.1043146 ]\n",
            " [ 5.4282947  -3.5951924   1.6294527   3.1440434 ]\n",
            " [-1.8827451  -1.3880116   1.2358577   0.50340617]\n",
            " [-1.8840098  -0.3906945   1.0490047  -0.60134614]],\n",
            " PyTorch result = \n",
            "[[-2.6196933  -0.5375238   1.9721649  -0.22582722]\n",
            " [-3.638156   -3.3526914  -0.42134583  2.1043146 ]\n",
            " [ 5.4282947  -3.5951924   1.6294527   3.1440434 ]\n",
            " [-1.8827451  -1.3880116   1.2358577   0.50340617]\n",
            " [-1.8840098  -0.3906945   1.0490047  -0.60134614]]\n",
            "\n",
            "Test 76: CUDA result = \n",
            "[[ 0.39433044  0.20562977 -0.1381258   1.8990215 ]\n",
            " [-3.2965453   2.5455604  -0.7861854   3.2656696 ]\n",
            " [-0.8599837   0.6381198  -0.03215766  0.9858087 ]\n",
            " [ 1.3271595  -0.01090938 -0.24212137 -0.12694693]\n",
            " [ 0.09786083  0.8560791  -0.55667585  1.5516148 ]],\n",
            " PyTorch result = \n",
            "[[ 0.39433038  0.20562977 -0.13812584  1.8990215 ]\n",
            " [-3.2965453   2.5455606  -0.7861854   3.2656698 ]\n",
            " [-0.8599837   0.6381198  -0.03215763  0.9858087 ]\n",
            " [ 1.3271594  -0.01090932 -0.24212137 -0.12694693]\n",
            " [ 0.09786083  0.8560791  -0.55667585  1.5516148 ]]\n",
            "\n",
            "Test 77: CUDA result = \n",
            "[[-2.5514357  -3.3315444   0.11586607 -0.28656343]\n",
            " [ 0.46240824  0.31753957 -1.3395426  -0.46807078]\n",
            " [-0.6331117  -1.9520719  -1.0487139  -0.69106936]\n",
            " [-0.15070061 -0.8180313  -1.2230511  -0.7008129 ]\n",
            " [ 0.9138441   2.989954   -1.5871692  -0.8968377 ]],\n",
            " PyTorch result = \n",
            "[[-2.5514357  -3.3315444   0.11586607 -0.28656343]\n",
            " [ 0.46240824  0.31753963 -1.3395426  -0.46807078]\n",
            " [-0.6331117  -1.9520719  -1.0487139  -0.69106936]\n",
            " [-0.15070061 -0.8180313  -1.2230511  -0.7008129 ]\n",
            " [ 0.9138442   2.989954   -1.5871692  -0.8968377 ]]\n",
            "\n",
            "Test 78: CUDA result = \n",
            "[[-0.18032384  1.6532205   3.707588   -0.48043633]\n",
            " [-0.05156094  2.5341423  -0.19598892 -2.2744937 ]\n",
            " [ 0.87786853  2.4911025  -2.1783376   2.3924193 ]\n",
            " [-1.0425972   1.4821627   2.7681692   0.83073825]\n",
            " [-0.5282583   2.120111   -1.2467343   1.8841641 ]],\n",
            " PyTorch result = \n",
            "[[-0.18032375  1.6532205   3.707588   -0.48043633]\n",
            " [-0.05156091  2.5341423  -0.19598898 -2.2744937 ]\n",
            " [ 0.87786865  2.4911025  -2.1783376   2.3924193 ]\n",
            " [-1.0425972   1.4821627   2.7681694   0.83073825]\n",
            " [-0.5282583   2.120111   -1.2467343   1.8841641 ]]\n",
            "\n",
            "Test 79: CUDA result = \n",
            "[[ 1.6122934  -0.01853645 -0.3600864  -2.8239722 ]\n",
            " [ 0.3660931   0.76249933  0.44295955 -0.3385929 ]\n",
            " [ 0.09284641  1.1750363   0.08079612  0.6248719 ]\n",
            " [ 0.19986199  0.58313715  0.21842153  0.02883387]\n",
            " [-0.96816134 -0.85458493  1.155114    1.1432376 ]],\n",
            " PyTorch result = \n",
            "[[ 1.6122934  -0.01853657 -0.36008647 -2.8239722 ]\n",
            " [ 0.3660931   0.76249933  0.44295955 -0.3385929 ]\n",
            " [ 0.09284644  1.1750363   0.08079612  0.62487197]\n",
            " [ 0.19986199  0.58313715  0.21842153  0.02883384]\n",
            " [-0.96816134 -0.85458493  1.1551142   1.1432376 ]]\n",
            "\n",
            "Test 80: CUDA result = \n",
            "[[-1.817595    1.6598047   0.6226967   1.4375702 ]\n",
            " [-0.5665822  -0.1553452  -0.26181793  2.1720505 ]\n",
            " [-0.7441186   2.3223367  -0.22728693  1.9329085 ]\n",
            " [-1.2314967   0.8318466   2.3463666   0.6067219 ]\n",
            " [-1.4468108   5.604404   -1.5341004   2.3215854 ]],\n",
            " PyTorch result = \n",
            "[[-1.817595    1.6598047   0.62269664  1.4375702 ]\n",
            " [-0.5665822  -0.1553452  -0.26181793  2.1720505 ]\n",
            " [-0.7441186   2.3223367  -0.22728693  1.9329085 ]\n",
            " [-1.2314968   0.8318466   2.3463666   0.6067219 ]\n",
            " [-1.4468107   5.6044035  -1.5341005   2.3215854 ]]\n",
            "\n",
            "Test 81: CUDA result = \n",
            "[[ 0.14654326  1.682147   -0.24371074  0.3326205 ]\n",
            " [ 1.8711426   2.275437    1.4464636   2.653474  ]\n",
            " [ 1.6281991   0.6080411  -0.68412775  1.8554943 ]\n",
            " [ 1.4281148   1.6221008   0.12273708  0.7839216 ]\n",
            " [ 3.1331406   0.9976647   0.41197923  2.9704356 ]],\n",
            " PyTorch result = \n",
            "[[ 0.14654326  1.682147   -0.24371079  0.3326205 ]\n",
            " [ 1.8711426   2.275437    1.4464636   2.653474  ]\n",
            " [ 1.6281991   0.6080411  -0.6841277   1.8554943 ]\n",
            " [ 1.4281148   1.6221008   0.12273708  0.7839216 ]\n",
            " [ 3.1331406   0.9976647   0.41197923  2.9704356 ]]\n",
            "\n",
            "Test 82: CUDA result = \n",
            "[[-0.21715236 -1.2794989   2.5092754   0.39414728]\n",
            " [ 0.8175501   1.8979492   0.6454377  -3.455224  ]\n",
            " [ 2.298248    5.6041155  -0.22782433 -4.321405  ]\n",
            " [ 2.881252    2.632516    0.5365168   3.1781955 ]\n",
            " [-1.9084222  -3.5820608   3.3858042  -1.3119619 ]],\n",
            " PyTorch result = \n",
            "[[-0.21715236 -1.2794989   2.5092754   0.39414728]\n",
            " [ 0.81755006  1.8979492   0.6454377  -3.455224  ]\n",
            " [ 2.298248    5.6041155  -0.22782433 -4.321405  ]\n",
            " [ 2.881252    2.632516    0.5365168   3.1781955 ]\n",
            " [-1.9084225  -3.5820608   3.3858042  -1.311962  ]]\n",
            "\n",
            "Test 83: CUDA result = \n",
            "[[ 0.32848978  0.2852596   2.195087    3.9132211 ]\n",
            " [ 0.42183435 -0.63889843 -3.1016688  -0.927831  ]\n",
            " [ 0.5000358  -0.818316   -2.268505   -0.46815807]\n",
            " [ 0.37539864 -1.152875   -5.839004   -3.5358827 ]\n",
            " [ 1.1067631   1.0571135  -3.6157131   1.0794842 ]],\n",
            " PyTorch result = \n",
            "[[ 0.32848978  0.2852596   2.195087    3.9132211 ]\n",
            " [ 0.42183435 -0.63889843 -3.1016688  -0.927831  ]\n",
            " [ 0.5000358  -0.818316   -2.268505   -0.46815813]\n",
            " [ 0.37539864 -1.152875   -5.839004   -3.5358827 ]\n",
            " [ 1.1067631   1.0571135  -3.6157131   1.0794843 ]]\n",
            "\n",
            "Test 84: CUDA result = \n",
            "[[ 0.9387185  -0.5093683   0.735511    0.6383014 ]\n",
            " [ 2.7579362  -0.7696635   0.38347274 -0.4226315 ]\n",
            " [ 1.9326549  -0.9414663   0.6108315   0.4650113 ]\n",
            " [ 1.4612145   0.32551187  0.22058007 -1.1490881 ]\n",
            " [ 2.2997525  -0.81914806  0.5234674   0.03105164]],\n",
            " PyTorch result = \n",
            "[[ 0.9387185  -0.5093683   0.73551106  0.6383014 ]\n",
            " [ 2.7579362  -0.7696636   0.38347274 -0.4226315 ]\n",
            " [ 1.9326549  -0.9414663   0.6108315   0.4650113 ]\n",
            " [ 1.4612147   0.32551187  0.22058007 -1.1490881 ]\n",
            " [ 2.2997525  -0.81914806  0.5234674   0.0310517 ]]\n",
            "\n",
            "Test 85: CUDA result = \n",
            "[[ 0.97546744  0.0383625  -0.49732006 -3.1569514 ]\n",
            " [ 0.59925425  2.188482   -1.183923   -1.6816617 ]\n",
            " [-0.8198234  -2.5622199   5.139312    1.390584  ]\n",
            " [-0.51597714  0.84816325  2.2519522   1.3763776 ]\n",
            " [-0.6092819  -1.2727157   1.5993599  -2.1087263 ]],\n",
            " PyTorch result = \n",
            "[[ 0.97546744  0.03836247 -0.49732018 -3.1569514 ]\n",
            " [ 0.59925425  2.188482   -1.183923   -1.6816618 ]\n",
            " [-0.8198234  -2.5622199   5.139312    1.390584  ]\n",
            " [-0.51597714  0.84816337  2.2519522   1.3763776 ]\n",
            " [-0.609282   -1.2727157   1.59936    -2.1087265 ]]\n",
            "\n",
            "Test 86: CUDA result = \n",
            "[[-1.773947    0.76795393  1.4592602   1.3045404 ]\n",
            " [-1.3505306   0.27343112  0.6053597  -0.376243  ]\n",
            " [-1.7580242   0.33103222  1.6993892  -0.78339034]\n",
            " [-1.0333664  -0.2026729   0.6607611  -0.7395286 ]\n",
            " [-0.47447056 -0.96590304  1.172156    0.02742314]],\n",
            " PyTorch result = \n",
            "[[-1.773947    0.7679538   1.4592602   1.3045406 ]\n",
            " [-1.3505306   0.27343112  0.6053597  -0.37624294]\n",
            " [-1.7580242   0.33103222  1.6993892  -0.78339034]\n",
            " [-1.0333663  -0.2026729   0.6607612  -0.73952866]\n",
            " [-0.47447056 -0.96590304  1.172156    0.02742308]]\n",
            "\n",
            "Test 87: CUDA result = \n",
            "[[ 1.084845   -0.4631294   0.4616797  -1.1717182 ]\n",
            " [-0.84192866  1.4398327  -1.3079758  -2.6064668 ]\n",
            " [-0.527711    0.09950984  0.73479545 -3.3003993 ]\n",
            " [-0.8865518  -2.6883469  -1.0885203  -1.7072554 ]\n",
            " [-1.7262723  -3.310459   -1.1123533  -2.4582841 ]],\n",
            " PyTorch result = \n",
            "[[ 1.0848451  -0.4631294   0.4616797  -1.1717181 ]\n",
            " [-0.84192866  1.4398327  -1.3079758  -2.6064668 ]\n",
            " [-0.52771086  0.09950984  0.73479545 -3.3003993 ]\n",
            " [-0.8865518  -2.6883469  -1.0885203  -1.7072554 ]\n",
            " [-1.7262723  -3.3104587  -1.1123533  -2.4582841 ]]\n",
            "\n",
            "Test 88: CUDA result = \n",
            "[[ 0.06511575  0.79889834  0.32206017  1.2381753 ]\n",
            " [ 1.8322258  -1.3348088   1.0698476  -2.7821293 ]\n",
            " [-0.2845409   2.1694882   2.9812217   1.6357149 ]\n",
            " [ 0.60617924  0.3929937   0.91989374 -0.25452283]\n",
            " [ 1.4892861  -1.7927943  -0.7029405  -1.221616  ]],\n",
            " PyTorch result = \n",
            "[[ 0.06511575  0.79889834  0.32206017  1.2381753 ]\n",
            " [ 1.8322258  -1.3348088   1.0698476  -2.7821293 ]\n",
            " [-0.2845409   2.1694884   2.981222    1.6357149 ]\n",
            " [ 0.60617924  0.3929937   0.91989374 -0.25452283]\n",
            " [ 1.4892861  -1.7927943  -0.7029405  -1.221616  ]]\n",
            "\n",
            "Test 89: CUDA result = \n",
            "[[ 1.3114266  -0.19094431  1.221137    2.021768  ]\n",
            " [-1.6013291  -3.0844893   1.3597065  -0.88323045]\n",
            " [ 0.11433873 -2.069465    1.1789073   0.17106394]\n",
            " [-1.3394523  -3.0579038   1.2123758  -0.8501961 ]\n",
            " [-2.1973119  -3.9682865   1.0291125  -1.773137  ]],\n",
            " PyTorch result = \n",
            "[[ 1.3114266  -0.19094431  1.221137    2.021768  ]\n",
            " [-1.6013291  -3.0844893   1.3597066  -0.88323045]\n",
            " [ 0.11433873 -2.069465    1.1789073   0.17106396]\n",
            " [-1.3394523  -3.0579038   1.2123758  -0.8501961 ]\n",
            " [-2.1973119  -3.9682865   1.0291125  -1.773137  ]]\n",
            "\n",
            "Test 90: CUDA result = \n",
            "[[-1.1837876   1.5386889  -1.32194     1.6588498 ]\n",
            " [-3.0054836   1.3396063  -1.1816987   2.865539  ]\n",
            " [-1.1153514   2.1414764  -0.5345289   1.7416432 ]\n",
            " [-1.9564365   0.50809324 -2.1355693  -2.1121278 ]\n",
            " [-1.867346    1.539415   -1.2807512   3.307827  ]],\n",
            " PyTorch result = \n",
            "[[-1.1837876   1.5386889  -1.32194     1.6588498 ]\n",
            " [-3.0054836   1.3396063  -1.1816987   2.865539  ]\n",
            " [-1.1153514   2.1414764  -0.53452885  1.7416433 ]\n",
            " [-1.9564365   0.50809324 -2.1355693  -2.1121283 ]\n",
            " [-1.867346    1.539415   -1.2807512   3.307827  ]]\n",
            "\n",
            "Test 91: CUDA result = \n",
            "[[-0.6608509  -1.676219    0.37737525 -1.533005  ]\n",
            " [-0.69981414 -2.0966585  -0.8539107   0.44837332]\n",
            " [ 2.098244   -0.33431268  1.9061383  -3.9918113 ]\n",
            " [-0.17149486 -1.8058726  -0.5334476  -0.04075956]\n",
            " [ 0.01583014 -1.7245654  -1.5422059   1.9666169 ]],\n",
            " PyTorch result = \n",
            "[[-0.6608509  -1.676219    0.37737527 -1.533005  ]\n",
            " [-0.69981414 -2.0966585  -0.8539107   0.44837332]\n",
            " [ 2.098244   -0.33431268  1.9061383  -3.9918113 ]\n",
            " [-0.17149486 -1.8058726  -0.5334476  -0.04075956]\n",
            " [ 0.01583005 -1.7245654  -1.5422059   1.9666169 ]]\n",
            "\n",
            "Test 92: CUDA result = \n",
            "[[ 1.6037065   3.5221415  -1.722242    1.209475  ]\n",
            " [-0.69510454  0.29186893  4.0037284  -0.2350791 ]\n",
            " [-1.0163234   1.725333    0.9654532  -3.1992972 ]\n",
            " [ 0.14571947  1.1567414   3.8100777  -1.0063195 ]\n",
            " [-1.5087456   0.38933158  2.172596   -0.69566214]],\n",
            " PyTorch result = \n",
            "[[ 1.6037065   3.5221415  -1.722242    1.209475  ]\n",
            " [-0.69510454  0.29186904  4.0037284  -0.23507911]\n",
            " [-1.0163234   1.7253329   0.96545315 -3.1992972 ]\n",
            " [ 0.1457195   1.1567414   3.8100777  -1.0063195 ]\n",
            " [-1.5087456   0.38933158  2.172596   -0.69566214]]\n",
            "\n",
            "Test 93: CUDA result = \n",
            "[[ 0.43772137 -3.1422126  -2.8606803   0.62577844]\n",
            " [-4.758512   -8.329368    5.018285    4.63843   ]\n",
            " [-4.2006397  -8.2024555   3.0387118   4.5523477 ]\n",
            " [-1.9455777  -0.6401727  -0.37865043 -0.845064  ]\n",
            " [-5.172966   -4.6613855   5.4471703   2.1574297 ]],\n",
            " PyTorch result = \n",
            "[[ 0.43772137 -3.1422126  -2.8606803   0.62577844]\n",
            " [-4.758512   -8.329368    5.018285    4.63843   ]\n",
            " [-4.2006397  -8.2024555   3.0387118   4.5523477 ]\n",
            " [-1.9455777  -0.6401727  -0.37865043 -0.845064  ]\n",
            " [-5.172966   -4.6613855   5.44717     2.1574297 ]]\n",
            "\n",
            "Test 94: CUDA result = \n",
            "[[ 2.0583432   0.10933691 -0.6204363  -4.084402  ]\n",
            " [-0.20058066 -1.5961953   2.7691116  -1.6978564 ]\n",
            " [-0.01381633 -0.578117    0.0761205  -1.3416259 ]\n",
            " [ 1.5662038  -0.6056289   1.613014   -4.185155  ]\n",
            " [-0.81654876 -2.3093867   4.851685   -1.5528924 ]],\n",
            " PyTorch result = \n",
            "[[ 2.0583432   0.10933691 -0.62043643 -4.084402  ]\n",
            " [-0.20058066 -1.5961953   2.7691116  -1.6978564 ]\n",
            " [-0.01381636 -0.578117    0.0761205  -1.3416259 ]\n",
            " [ 1.5662038  -0.6056289   1.613014   -4.185155  ]\n",
            " [-0.81654876 -2.3093867   4.851685   -1.5528923 ]]\n",
            "\n",
            "Test 95: CUDA result = \n",
            "[[ 0.47551474  1.0814606  -0.03756833 -1.5396484 ]\n",
            " [ 0.5056738  -4.428497   -0.22813152 -2.8052456 ]\n",
            " [ 0.31656367  0.8833291  -0.6531793  -1.5211344 ]\n",
            " [-0.22385013  1.6369166  -0.5109894   0.6432862 ]\n",
            " [ 0.5083357  -4.559274   -1.5662328  -3.9411197 ]],\n",
            " PyTorch result = \n",
            "[[ 0.47551477  1.0814606  -0.03756833 -1.5396484 ]\n",
            " [ 0.5056738  -4.4284973  -0.22813153 -2.8052456 ]\n",
            " [ 0.31656367  0.8833291  -0.6531793  -1.5211344 ]\n",
            " [-0.22385013  1.6369166  -0.5109894   0.6432862 ]\n",
            " [ 0.5083357  -4.559274   -1.5662328  -3.9411197 ]]\n",
            "\n",
            "Test 96: CUDA result = \n",
            "[[ 2.0375252  -0.370521    1.252969    1.9739017 ]\n",
            " [ 1.9386754   1.0907516   2.591528   -0.16855502]\n",
            " [ 0.9790616   1.7627292   2.3278408  -0.21388435]\n",
            " [ 1.4981322  -0.5585143   0.4744959   2.8334124 ]\n",
            " [ 1.2212275  -1.2153561   2.2271633   3.5524604 ]],\n",
            " PyTorch result = \n",
            "[[ 2.0375252  -0.3705209   1.252969    1.9739017 ]\n",
            " [ 1.9386754   1.0907516   2.591528   -0.16855502]\n",
            " [ 0.9790616   1.762729    2.3278408  -0.21388435]\n",
            " [ 1.4981322  -0.5585143   0.4744959   2.8334124 ]\n",
            " [ 1.2212275  -1.2153559   2.2271633   3.5524604 ]]\n",
            "\n",
            "Test 97: CUDA result = \n",
            "[[-1.3460273   1.247842    0.34518343 -1.4997361 ]\n",
            " [ 0.23486069  1.4354266   0.93234336 -2.060759  ]\n",
            " [ 2.2745302   2.308126    0.16555464 -2.842079  ]\n",
            " [-4.085049    1.808625    0.5698788  -1.1631598 ]\n",
            " [-2.0115666   1.8151133  -0.46149364 -1.4868321 ]],\n",
            " PyTorch result = \n",
            "[[-1.3460273   1.247842    0.34518343 -1.4997361 ]\n",
            " [ 0.23486064  1.4354266   0.93234336 -2.060759  ]\n",
            " [ 2.27453     2.308126    0.16555464 -2.8420787 ]\n",
            " [-4.085049    1.808625    0.5698788  -1.1631598 ]\n",
            " [-2.0115666   1.8151133  -0.46149364 -1.4868321 ]]\n",
            "\n",
            "Test 98: CUDA result = \n",
            "[[ 1.842588   -1.6028286  -6.2245216  -2.0306702 ]\n",
            " [-3.7699552   2.2167022   4.2466793   2.4703574 ]\n",
            " [ 1.4657791  -1.405849    0.16511762  1.7953955 ]\n",
            " [-2.2781425   1.331696   -1.1601083   1.708031  ]\n",
            " [-2.9587715   1.7134578  -0.35594463  0.23607814]],\n",
            " PyTorch result = \n",
            "[[ 1.842588   -1.6028286  -6.2245216  -2.0306702 ]\n",
            " [-3.7699552   2.2167022   4.2466793   2.470358  ]\n",
            " [ 1.4657791  -1.4058489   0.1651175   1.7953955 ]\n",
            " [-2.2781425   1.331696   -1.1601083   1.7080308 ]\n",
            " [-2.9587712   1.7134578  -0.35594463  0.23607814]]\n",
            "\n",
            "Test 99: CUDA result = \n",
            "[[-0.36280406 -3.102091   -6.0370865  -0.6428975 ]\n",
            " [ 1.0435961  -1.8247955  -4.906949   -1.2172213 ]\n",
            " [ 0.9100263   0.48199323 -2.551699   -1.7588575 ]\n",
            " [-0.51884294  0.62575895 -1.7216015  -2.5162063 ]\n",
            " [-2.0968447   0.9335164  -2.5225258   0.182652  ]],\n",
            " PyTorch result = \n",
            "[[-0.36280406 -3.102091   -6.0370865  -0.6428975 ]\n",
            " [ 1.0435961  -1.8247955  -4.906949   -1.2172213 ]\n",
            " [ 0.9100263   0.48199323 -2.551699   -1.7588575 ]\n",
            " [-0.51884294  0.62575895 -1.7216015  -2.5162063 ]\n",
            " [-2.0968447   0.9335164  -2.5225258   0.182652  ]]\n",
            "\n",
            "Test 100: CUDA result = \n",
            "[[ 3.4269614  -0.41753447 -2.369763   -3.6704378 ]\n",
            " [-0.74437344  0.59813255  0.72767967 -0.9435202 ]\n",
            " [-0.2547183   2.3329115   0.57344025  2.2585068 ]\n",
            " [ 0.1472137   0.7256091  -0.13154244 -0.44967818]\n",
            " [ 0.4144442  -0.05565596 -0.7751224  -1.3336452 ]],\n",
            " PyTorch result = \n",
            "[[ 3.4269614  -0.41753447 -2.369763   -3.6704378 ]\n",
            " [-0.7443733   0.59813255  0.72767967 -0.9435203 ]\n",
            " [-0.25471833  2.3329113   0.57344025  2.2585068 ]\n",
            " [ 0.1472137   0.7256091  -0.13154244 -0.44967812]\n",
            " [ 0.41444424 -0.05565608 -0.7751224  -1.3336453 ]]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}